{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38c314c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import geojson\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from osgeo import gdal\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# custom functions\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.functions import grab_certain_file\n",
    "# TODO delete functions.py in data_preperation folder. Use main utils instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d9e91b",
   "metadata": {},
   "source": [
    "'''\n",
    "Read NSO tiles and annotations geojsons, convert lat/lon of tile to pixel coordinates and save pixel coordinates into\n",
    ".json file If more than on .json file can be saved as one via_regions.json.\n",
    "Source:  https://github.com/rl02898/detectron2-spacenet. JDP Edits:some and saving json with origins of tile in jsons to allow stiching back\n",
    "of the tiles.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6721563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ARGS function ###\n",
    "\n",
    "nso_path = \"../NSO_1000\"\n",
    "train_path = os.path.join(nso_path, \"train\")\n",
    "test_path = os.path.join(nso_path, \"test\")\n",
    "val_path = os.path.join(nso_path, \"val\")\n",
    "geojson_path = os.path.join(nso_path, \"geojsons\")\n",
    "small_tiles_path = os.path.join(nso_path, \"NSO_small_tiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b850ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide dataset and set a random seed for reproducibility of the splits for next script\n",
    "\n",
    "RANDOM_SEED = 560\n",
    "\n",
    "# Create JSONs for Detectron2 NO test set\n",
    "#nso_images = grab_certain_file(\".tif\", small_tiles_path)\n",
    "#train, val = train_test_split(nso_images, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "# Create JSONs for Detectron2 WITH test set\n",
    "nso_images = grab_certain_file(\".tif\", small_tiles_path)\n",
    "train, test = train_test_split(nso_images, test_size=0.20, random_state=RANDOM_SEED)\n",
    "train, val = train_test_split(train, test_size=0.25, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85d84ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geojson_to_json_pix_coords(dataset_split, small_tiles_path, geojson_path, dataset_path):\n",
    "    \"\"\"\n",
    "    Converts geojson annotations to JSON format with pixel coordinates.\n",
    "\n",
    "    Args:\n",
    "        dataset_split (list): List of image files in the dataset split:train,test or val\n",
    "        small_tiles_path (str): Path to the directory containing the small tiles.tif.\n",
    "        geojson_path (str): Path to the directory containing the geojson files of the annotations.\n",
    "        dataset_path (str): Path to the datasets train, val or test.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Description:\n",
    "        This function iterates over each image in the dataset split and converts the corresponding geojson\n",
    "        annotations to JSON format, with pixel coordinates calculated using GDAL. It creates a dictionary\n",
    "        containing image file information and a regions dictionary storing the asset footprints with their\n",
    "        respective shape attributes. The resulting JSON file is saved as \"nso.json\" in the dataset path.Images \n",
    "        with no annotation have regions= {}\n",
    "    \"\"\"\n",
    "  \n",
    "    # Create an empty dictionary to store the training/test/val set of annotations and their pixel coordinates\n",
    "    dataset_dict = {}\n",
    "\n",
    "    # Loop over each image in the training set\n",
    "    for file in tqdm(dataset_split, desc=f\"Creating JSONs for Detectron2 on {dataset_path}\", ncols=150, bar_format=\"{l_bar}{bar:10}{r_bar}\"):\n",
    "        file_path = os.path.join(small_tiles_path, file)\n",
    "        img_id = file.split(\".tif\")[0]\n",
    "        geojson_image = os.path.join(geojson_path, f\"{img_id}.geojson\")\n",
    "\n",
    "        #Not all tiles have annotations, thus:\n",
    "        if os.path.exists(geojson_image):\n",
    "\n",
    "            # Load the geojson in gj\n",
    "            with open(geojson_image) as f:\n",
    "                gj = geojson.load(f)\n",
    "\n",
    "            # Create a dictionary to store the regions (annotations spatial features) for the image\n",
    "            regions = {}\n",
    "            num_buildings = len(gj[\"features\"])\n",
    "            #print (num_buildings) \n",
    "\n",
    "            # Open the image with gdal to get pixel size and origin if feature exists\n",
    "            #if num_buildings > 0:\n",
    "            gdal_image = gdal.Open(file_path)\n",
    "\n",
    "            # Get the pixel width and height(0.5 for nso) and the origin coordinates\n",
    "            #https://www.gis.usu.edu/~chrisg/python/2009/lectures/ospy_slides4.pdf\n",
    "            pixel_width, pixel_height = gdal_image.GetGeoTransform()[1], gdal_image.GetGeoTransform()[5]\n",
    "            originX, originY = gdal_image.GetGeoTransform()[0], gdal_image.GetGeoTransform()[3]\n",
    "\n",
    "            # Loop over each building/assets in the image\n",
    "            for i in range(num_buildings):\n",
    "\n",
    "                # Get the polygon points for the asset\n",
    "                #https://stackoverflow.com/questions/23306653/python-accessing-nested-json-data\n",
    "                points = gj[\"features\"][i][\"geometry\"][\"coordinates\"][0]\n",
    "\n",
    "                # If there is only one point, unwarp it=>check\n",
    "                if len(points) == 1:\n",
    "                    points = points[0]\n",
    "\n",
    "                #Empty lists to store pixel coordinates\n",
    "                all_points_x, all_points_y = [], []\n",
    "\n",
    "                # Convert the lat/long points to pixel coordinates by substacting origin\n",
    "                for j in range(len(points)):\n",
    "                    all_points_x.append(int(round((points[j][0] - originX) / pixel_width)))\n",
    "                    all_points_y.append(int(round((points[j][1] - originY) / pixel_height)))\n",
    "\n",
    "                # Create a dictionary to store the asset footprint\n",
    "                regions[str(i)] = {\"shape_attributes\":\n",
    "                                       {\"name\": \"polygon\",\n",
    "                                        \"all_points_x\": all_points_x,\n",
    "                                        \"all_points_y\": all_points_y,\n",
    "                                        \"category\": 0\n",
    "                                       },\n",
    "                                   \"region_attributes\": {}\n",
    "                                  }\n",
    "                #print (regions)\n",
    "            #Should probably save origin x and y here but we still have the og tiles and imgid and allow to stich tiles back together\n",
    "            #TODO: same for tiles without annot.Eg create json with empty regions in the else\n",
    "            dictionary = {\"file_ref\": '',\n",
    "                          \"size\": os.path.getsize(file_path),\n",
    "                          \"filename\": file.replace(\".tif\", \".png\"),\n",
    "                          \"base64_img_data\": '',\n",
    "                          \"file_attributes\": {},\n",
    "                          \"regions\": regions,\n",
    "                          \"origin_x\": originX,\n",
    "                          \"origin_y\": originY\n",
    "                         }\n",
    "            #print (dictionary)\n",
    "            dataset_dict[file.replace(\".tif\", \".png\")] = dictionary\n",
    "        else:\n",
    "            # region is empty\n",
    "            \n",
    "            # stl save data dic with empty regions and origins\n",
    "            gdal_image = gdal.Open(file_path)\n",
    "            # Get the pixel width and height(0.5 for nso) and the origin coordinates\n",
    "            #https://www.gis.usu.edu/~chrisg/python/2009/lectures/ospy_slides4.pdf\n",
    "            pixel_width, pixel_height = gdal_image.GetGeoTransform()[1], gdal_image.GetGeoTransform()[5]\n",
    "            originX, originY = gdal_image.GetGeoTransform()[0], gdal_image.GetGeoTransform()[3]\n",
    "            \n",
    "            dictionary = {\"file_ref\": '',\n",
    "                          \"size\": os.path.getsize(file_path),\n",
    "                          \"filename\": file.replace(\".tif\", \".png\"),\n",
    "                          \"base64_img_data\": '',\n",
    "                          \"file_attributes\": {},\n",
    "                          \"regions\": {},\n",
    "                          \"origin_x\": originX,\n",
    "                          \"origin_y\": originY\n",
    "                         }\n",
    "            #print (dictionary)\n",
    "        dataset_dict[file.replace(\".tif\", \".png\")] = dictionary\n",
    "            \n",
    "    jsons_path = os.path.join(dataset_path,\"nso_with_no_annotations.json\")\n",
    "    with open(jsons_path, \"w\") as f:\n",
    "        json.dump(dataset_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1ce8c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating JSONs for Detectron2 on ../NSO_1000/val: 100%|██████████| 4949/4949 [00:06<00:00, 819.62it/s] \n"
     ]
    }
   ],
   "source": [
    "geojson_to_json_pix_coords(train, small_tiles_path, geojson_path, train_path)\n",
    "geojson_to_json_pix_coords(test, small_tiles_path, geojson_path, test_path)\n",
    "geojson_to_json_pix_coords(val, small_tiles_path, geojson_path, val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e1c8284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done creating JSONs train\n",
      "Done creating JSONs test\n",
      "Done creating JSONs val\n"
     ]
    }
   ],
   "source": [
    "# Create single via_region_data training dataset => can be skipped if only one .json file.=>But then change file name\n",
    "for d in [\"train\", \"test\", \"val\"]:\n",
    "    jsons = [os.path.join(nso_path, d, \"nso_with_no_annotations.json.json\")]\n",
    "    result = {}\n",
    "    for file in jsons:\n",
    "        with open(file, \"r\") as f:\n",
    "            loaded = json.load(f)\n",
    "            \n",
    "        #https://realpython.com/iterate-through-dictionary-python/\n",
    "        for key, value in loaded.items():\n",
    "            result[key] = value\n",
    "    via_region_p = os.path.join(nso_path, d, \"via_region_data__with_no_annotations.json\")\n",
    "    with open(via_region_p, \"w\") as file:\n",
    "        json.dump(result, file)\n",
    "        \n",
    "    print(f\"Done creating JSONs {d}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2da526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check is the regions are well writen\n",
    "file_path_json = \"../NSO_1000/val/nso_with_no_annotations.json\"\n",
    "\n",
    "with open (file_path_json) as f:\n",
    "    data = json.load(f)\n",
    "key = \"25_20220730_110228_SV2-01_SV_RD_8bit_RGB_50cm_Ketelmeer_24000_30000.png\"\n",
    "\n",
    "\n",
    "if key in data:\n",
    "    print(data[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e63eec1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
