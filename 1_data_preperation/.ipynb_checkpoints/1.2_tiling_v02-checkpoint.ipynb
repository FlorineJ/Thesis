{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scistor/ivm/fjo101/miniconda3/envs/nso/lib/python3.9/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "2024-05-07 09:12:40.129170: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-07 09:12:44.493881: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-07 09:12:53.066827: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import pygeos\n",
    "import shapely\n",
    "import rasterio\n",
    "import json\n",
    "import pyproj\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# custom functions\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.tiling import split_geotiff, reproject, split_annotations_to_geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Split geotiff args ###\n",
    "\n",
    "raster_folder = Path(\"../Satellite/big_tiles_test\")\n",
    "tile_output_folder = Path(\"../Satellite/small_tiles_test\")\n",
    "#make output directory if does not exist\n",
    "if not os.path.exists(tile_output_folder):\n",
    "    os.makedirs(tile_output_folder)\n",
    "#details of small tiles\n",
    "width = 1000 #width of the new tiles\n",
    "height = 1000 #height of the new tiles\n",
    "nso_pix = 1 #pixel size of the raster\n",
    "\n",
    "### 2. Reproject geodataframe of a annotation shapefile args ###\n",
    "\n",
    "annotations_crs = \"epsg:4326\"\n",
    "raster_crs = \"epsg:3857\"\n",
    "\n",
    "\n",
    "### 3.Spit annotations args ###\n",
    "\n",
    "# Make folder for geojsons\n",
    "json_folder = Path(\"../NSO/geojsons_test\")\n",
    "if not os.path.exists(json_folder):\n",
    "    os.makedirs(json_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:38<00:00, 32.80s/it]\n"
     ]
    }
   ],
   "source": [
    "### Spliting a list of raster into several tiles of x width and y height skipping black tiles ###\n",
    "\n",
    "#loop through the big tiles (rasters) and split them into smaller tiles\n",
    "split_geotiff(raster_folder, tile_output_folder, width, height, nso_pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reprojection completed.\n"
     ]
    }
   ],
   "source": [
    "### Reproject the DataFrame of an annotation shapefile CRS to the target CRS as the raster tiles ###\n",
    "\n",
    "# Define the directory containing your GeoJSON files\n",
    "annotations_path = Path(\"../Satellite/geojsons_test\")\n",
    "output_path = Path(\"../Satellite/geojsons_test_converted\")\n",
    "output_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Define the source and target CRS\n",
    "annotations_crs = \"epsg:4326\"\n",
    "raster_crs = \"epsg:3857\"\n",
    "\n",
    "# for filename in os.listdir(annotations_path):\n",
    "#         if filename.endswith(\".geojson\"):\n",
    "#             file_path = os.path.join(annotations_path, filename)\n",
    "#             gdf = gpd.read_file(file_path)\n",
    "\n",
    "#             if gdf.crs is None:\n",
    "#                 gdf.set_crs(annotations_crs, inplace=True)\n",
    "            \n",
    "#             # Ensuring type information is present\n",
    "#             if 'type' in gdf.columns:\n",
    "#                 gdf = gdf.to_crs(raster_crs)\n",
    "#                 output_file_path = os.path.join(output_path, f\"reprojected_{filename}\")\n",
    "#                 gdf.to_file(output_file_path, driver='GeoJSON')\n",
    "#             else:\n",
    "#                 print(f\"No 'type' column found in {filename}\")\n",
    "\n",
    "print(\"Reprojection completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique types found:\n",
      "warehouse\n",
      "vehicles\n",
      "land\n",
      "roro\n",
      "storage\n",
      "bulk\n",
      "oil/gas\n",
      "industry\n",
      "break\n",
      "scrap\n",
      "container\n",
      "mixed\n",
      "refinery\n",
      "other\n",
      "wood\n",
      "raw\n",
      "steel\n"
     ]
    }
   ],
   "source": [
    "###Extract labels of land uses and print unique types \n",
    "def print_unique_types(annotations_path):\n",
    "    unique_types = set()  # Using a set to avoid duplicate types\n",
    "\n",
    "    # Check all GeoJSON files in the given directory\n",
    "    for filename in os.listdir(annotations_path):\n",
    "        if filename.endswith(\".geojson\"):\n",
    "            file_path = os.path.join(annotations_path, filename)\n",
    "            try:\n",
    "                # Load the GeoJSON file into a GeoDataFrame\n",
    "                gdf = gpd.read_file(file_path)\n",
    "                \n",
    "                # Check if 'type' column exists in the GeoDataFrame\n",
    "                if 'type' in gdf.columns:\n",
    "                    # Update the set with unique types found in this file\n",
    "                    unique_types.update(gdf['type'].unique())\n",
    "                else:\n",
    "                    print(f\"No 'type' column found in {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {filename}: {e}\")\n",
    "\n",
    "    # Print all unique types collected from all files\n",
    "    print(\"Unique types found:\")\n",
    "    for typ in unique_types:\n",
    "        print(typ)\n",
    "\n",
    "annotations_path =  Path(\"../Satellite/geojsons_test\")\n",
    "print_unique_types(annotations_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "5bc4db46b6a73bd30a11a2fa3e93f40c6d7b47ce177475cde816571bd5c02b40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
