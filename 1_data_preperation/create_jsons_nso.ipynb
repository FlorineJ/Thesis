{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38c314c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import geojson\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from osgeo import gdal\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# custom functions\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.functions import grab_certain_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37186f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat train val and test folder in NSO directory\n",
    "\n",
    "root_path = 'NSO'\n",
    "folders = ['train','test','val']\n",
    "for folder in folders:\n",
    "    os.mkdir(os.path.join(root_path,folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7343cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 560\n",
    "\n",
    "nso_train = \"NSO/nso_all\"\n",
    "nso_geojson = \"NSO/geojsons_annotations_nso\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e88d7bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create JSONs for Detectron2\n",
    "nso_images = grab_certain_file(\".tif\", nso_train)\n",
    "train, val = train_test_split(nso_images, test_size=0.2, random_state=RANDOM_SEED)\n",
    "train_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f447e756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating JSONs for Detectron2 on NSO: 100%|██████████| 4592/4592 [00:00<00:00, 76836.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# Training set\n",
    "\n",
    "#Could probably save origin x and y to stich tiles back together at a later stage\n",
    "for file in tqdm(train, desc=\"Creating JSONs for Detectron2 on NSO\", ncols=150, bar_format=\"{l_bar}{bar:10}{r_bar}\"):\n",
    "    file_path = os.path.join(nso_train, file)\n",
    "    img_id = file.split(\".tif\")[0]\n",
    "    geojson_path = os.path.join(nso_geojson, f\"{img_id}.geojson\")\n",
    "    #Not all tiles have annotations, thus:\n",
    "    if os.path.exists(geojson_path):        \n",
    "        with open(geojson_path) as f:\n",
    "            gj = geojson.load(f)\n",
    "        regions = {}\n",
    "        num_buildings = len(gj[\"features\"])\n",
    "        \n",
    "        if num_buildings > 0:\n",
    "            gdal_image = gdal.Open(file_path)\n",
    "            #https://www.gis.usu.edu/~chrisg/python/2009/lectures/ospy_slides4.pdf\n",
    "            pixel_width, pixel_height = gdal_image.GetGeoTransform()[1], gdal_image.GetGeoTransform()[5]\n",
    "            originX, originY = gdal_image.GetGeoTransform()[0], gdal_image.GetGeoTransform()[3]\n",
    "\n",
    "            for i in range(num_buildings):\n",
    "                #https://stackoverflow.com/questions/23306653/python-accessing-nested-json-data\n",
    "                points = gj[\"features\"][i][\"geometry\"][\"coordinates\"][0]\n",
    "                if len(points) == 1:\n",
    "                    points = points[0]\n",
    "\n",
    "                all_points_x, all_points_y = [], []\n",
    "                for j in range(len(points)):\n",
    "                    all_points_x.append(int(round((points[j][0] - originX) / pixel_width)))\n",
    "                    all_points_y.append(int(round((points[j][1] - originY) / pixel_height)))\n",
    "\n",
    "                regions[str(i)] = {\"shape_attributes\":\n",
    "                                       {\"name\": \"polygon\",\n",
    "                                        \"all_points_x\": all_points_x,\n",
    "                                        \"all_points_y\": all_points_y,\n",
    "                                        \"category\": 0\n",
    "                                       },\n",
    "                                   \"region_attributes\": {}\n",
    "                                  }\n",
    "        #Should probably save origin x and y here but we still have the og tiles and imgid\n",
    "        dictionary = {\"file_ref\": '',\n",
    "                      \"size\": os.path.getsize(file_path),\n",
    "                      \"filename\": file.replace(\".tif\", \".png\"),\n",
    "                      \"base64_img_data\": '',\n",
    "                      \"file_attributes\": {},\n",
    "                      \"regions\": regions\n",
    "                     }\n",
    "\n",
    "        train_dict[file.replace(\".tif\", \".png\")] = dictionary\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "with open(\"NSO/train/nso.json\", \"w\") as f:\n",
    "    json.dump(train_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f301403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating JSONs for Detectron2 on 1_Rio_val: 100%|██████████| 1148/1148 [00:00<00:00, 8303.28it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation set\n",
    "val_dict = {}\n",
    "\n",
    "for file in tqdm(val, desc=\"Creating JSONs for Detectron2 on 1_Rio_val\", ncols=150, bar_format=\"{l_bar}{bar:10}{r_bar}\"):\n",
    "    file_path = os.path.join(nso_train, file)\n",
    "    img_id = file.split(\".tif\")[0]\n",
    "    geojson_path = os.path.join(nso_geojson, f\"{img_id}.geojson\")\n",
    "    if os.path.exists(geojson_path): \n",
    "        with open(geojson_path) as f:\n",
    "            gj = geojson.load(f)\n",
    "\n",
    "        regions = {}\n",
    "        num_buildings = len(gj[\"features\"])\n",
    "        if num_buildings > 0:\n",
    "            gdal_image = gdal.Open(file_path)\n",
    "            pixel_width, pixel_height = gdal_image.GetGeoTransform()[1], gdal_image.GetGeoTransform()[5]\n",
    "            originX, originY = gdal_image.GetGeoTransform()[0], gdal_image.GetGeoTransform()[3]\n",
    "\n",
    "            for i in range(num_buildings):\n",
    "                points = gj[\"features\"][i][\"geometry\"][\"coordinates\"][0]\n",
    "                if len(points) == 1:\n",
    "                    points = points[0]\n",
    "\n",
    "                all_points_x, all_points_y = [], []\n",
    "                for j in range(len(points)):\n",
    "                    all_points_x.append(int(round((points[j][0] - originX) / pixel_width)))\n",
    "                    all_points_y.append(int(round((points[j][1] - originY) / pixel_height)))\n",
    "\n",
    "                regions[str(i)] = {\"shape_attributes\":\n",
    "                                       {\"name\": \"polygon\",\n",
    "                                        \"all_points_x\": all_points_x,\n",
    "                                        \"all_points_y\": all_points_y,\n",
    "                                        \"category\": 0\n",
    "                                       },\n",
    "                                   \"region_attributes\": {}\n",
    "                                  }\n",
    "\n",
    "        dictionary = {\"file_ref\": '',\n",
    "                      \"size\": os.path.getsize(file_path),\n",
    "                      \"filename\": file.replace(\".tif\", \".png\"),\n",
    "                      \"base64_img_data\": '',\n",
    "                      \"file_attributes\": {},\n",
    "                      \"regions\": regions\n",
    "                     }\n",
    "\n",
    "        val_dict[file.replace(\".tif\", \".png\")] = dictionary\n",
    "\n",
    "with open(\"NSO/val/nso.json\", \"w\") as f:\n",
    "    json.dump(val_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a964211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create JSON for entire training dataset\n",
    "jsons = [\"NSO/train/nso.json\"]\n",
    "\n",
    "result = {}\n",
    "for file in jsons:\n",
    "    with open(file, \"r\") as f:\n",
    "        loaded = json.load(f)\n",
    "        \n",
    "    #https://realpython.com/iterate-through-dictionary-python/\n",
    "    for key, value in loaded.items():\n",
    "        result[key] = value\n",
    "\n",
    "with open(\"NSO/train/via_region_data.json\", \"w\") as file:\n",
    "    json.dump(result, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4426d33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done creating JSONs\n"
     ]
    }
   ],
   "source": [
    "# Create JSON for entire validation dataset\n",
    "jsons = [\"NSO/val/nso.json\"]\n",
    "\n",
    "result = {}\n",
    "for file in jsons:\n",
    "    with open(file, \"r\") as f:\n",
    "        loaded = json.load(f)\n",
    "    for key, value in loaded.items():\n",
    "        result[key] = value\n",
    "\n",
    "with open(\"NSO/val/via_region_data.json\", \"w\") as file:\n",
    "    json.dump(result, file)\n",
    "\n",
    "print(\"Done creating JSONs\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
