{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38c314c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import geojson\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from osgeo import gdal\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# custom functions\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.functions import grab_certain_file\n",
    "from utils.create_jsons import geojson_to_json_pix_coords\n",
    "# TODO delete functions.py in data_preperation folder. Use main utils instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d9e91b",
   "metadata": {},
   "source": [
    "'''\n",
    "Read NSO tiles and annotations geojsons, convert lat/lon of tile to pixel coordinates and save pixel coordinates into\n",
    ".json file If more than one .json file can be saved as one via_regions.json.\n",
    "Source:  https://github.com/rl02898/detectron2-spacenet. JDP Edits:some and saving json with origins of tile in jsons to allow stiching back of the tiles. Add empty json for tiles without nnotation to allow their reading in D2.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6721563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ARGS function ###\n",
    "\n",
    "nso_path = \"../NSO\"\n",
    "train_path = os.path.join(nso_path, \"train\")\n",
    "test_path = os.path.join(nso_path, \"test\")\n",
    "val_path = os.path.join(nso_path, \"val\")\n",
    "geojson_path = os.path.join(nso_path, \"geojsons\")\n",
    "small_tiles_path = os.path.join(nso_path, \"NSO_small_tiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b850ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide dataset and set a random seed for reproducibility of the splits for next script\n",
    "\n",
    "RANDOM_SEED = 560\n",
    "\n",
    "# Create JSONs for Detectron2 NO test set\n",
    "#nso_images = grab_certain_file(\".tif\", small_tiles_path)\n",
    "#train, val = train_test_split(nso_images, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "# Create JSONs for Detectron2 WITH test set\n",
    "nso_images = grab_certain_file(\".tif\", small_tiles_path)\n",
    "train, test = train_test_split(nso_images, test_size=0.20, random_state=RANDOM_SEED)\n",
    "train, val = train_test_split(train, test_size=0.25, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1ce8c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating JSONs for Detectron2 on ../NSO/train: 100%|██████████| 78324/78324 [53:46<00:00, 24.27it/s]  \n",
      "Creating JSONs for Detectron2 on ../NSO/test: 100%|██████████| 26108/26108 [16:50<00:00, 25.84it/s]\n",
      "Creating JSONs for Detectron2 on ../NSO/val: 100%|██████████| 26108/26108 [15:47<00:00, 27.56it/s]\n"
     ]
    }
   ],
   "source": [
    "geojson_to_json_pix_coords(train, small_tiles_path, geojson_path, train_path)\n",
    "geojson_to_json_pix_coords(test, small_tiles_path, geojson_path, test_path)\n",
    "geojson_to_json_pix_coords(val, small_tiles_path, geojson_path, val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e1c8284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done creating JSONs train\n",
      "Done creating JSONs test\n",
      "Done creating JSONs val\n"
     ]
    }
   ],
   "source": [
    "# Create single via_region_data training dataset => can be skipped if only one .json file.=>But then change file name\n",
    "for d in [\"train\", \"test\", \"val\"]:\n",
    "    jsons = [os.path.join(nso_path, d, \"nso_with_empty_annotations.json\")]\n",
    "    result = {}\n",
    "    for file in jsons:\n",
    "        with open(file, \"r\") as f:\n",
    "            loaded = json.load(f)\n",
    "            \n",
    "        #https://realpython.com/iterate-through-dictionary-python/\n",
    "        for key, value in loaded.items():\n",
    "            result[key] = value\n",
    "    via_region_p = os.path.join(nso_path, d, \"via_region_data_with_empty_annotations.json\")\n",
    "    with open(via_region_p, \"w\") as file:\n",
    "        json.dump(result, file)\n",
    "        \n",
    "    print(f\"Done creating JSONs {d}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec2da526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Check is the regions are well writen\n",
    "\n",
    "train = \"../NSO/train/via_region_data_with_no_annotations.json\"\n",
    "val = \"../NSO/val/via_region_data_with_no_annotations.json\"\n",
    "test = \"../NSO/test/via_region_data_with_no_annotations.json\"\n",
    "pths = [train, val, test]\n",
    "\n",
    "dfs = []\n",
    "for path in pths:\n",
    "    df = pd.read_json(path, orient='index')\n",
    "    dfs.append(df)\n",
    "\n",
    "train_df = dfs[0]\n",
    "val_df = dfs[1]\n",
    "test_df = dfs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1daf4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no regions: 78028, with regions: 296\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_ref</th>\n",
       "      <th>size</th>\n",
       "      <th>filename</th>\n",
       "      <th>base64_img_data</th>\n",
       "      <th>file_attributes</th>\n",
       "      <th>regions</th>\n",
       "      <th>origin_x</th>\n",
       "      <th>origin_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66_20220903_111726_SV1-04_SV_RD_8bit_RGB_50cm_HoekVanHolland_18000_23000.png</th>\n",
       "      <td></td>\n",
       "      <td>3107342</td>\n",
       "      <td>66_20220903_111726_SV1-04_SV_RD_8bit_RGB_50cm_...</td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>73790.0</td>\n",
       "      <td>442478.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154_20220906_104537_SV1-03_SV_RD_8bit_RGB_50cm_Hardenberg_12000_26000.png</th>\n",
       "      <td></td>\n",
       "      <td>3007320</td>\n",
       "      <td>154_20220906_104537_SV1-03_SV_RD_8bit_RGB_50cm...</td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>242684.0</td>\n",
       "      <td>518504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59_20221102_105437_SV2-01_SV_RD_8bit_RGB_50cm_Echteld_13000_15000.png</th>\n",
       "      <td></td>\n",
       "      <td>3494018</td>\n",
       "      <td>59_20221102_105437_SV2-01_SV_RD_8bit_RGB_50cm_...</td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>160856.0</td>\n",
       "      <td>445873.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79_20220922_105204_SV1-04_SV_RD_8bit_RGB_50cm_Coevorden_16000_7000.png</th>\n",
       "      <td></td>\n",
       "      <td>3132536</td>\n",
       "      <td>79_20220922_105204_SV1-04_SV_RD_8bit_RGB_50cm_...</td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>246618.0</td>\n",
       "      <td>528318.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52_20221004_110216_SV1-03_SV_RD_8bit_RGB_50cm_WijkBijDuurstede_13000_24000.png</th>\n",
       "      <td></td>\n",
       "      <td>3199257</td>\n",
       "      <td>52_20221004_110216_SV1-03_SV_RD_8bit_RGB_50cm_...</td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>154632.0</td>\n",
       "      <td>444063.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   file_ref     size  \\\n",
       "66_20220903_111726_SV1-04_SV_RD_8bit_RGB_50cm_H...           3107342   \n",
       "154_20220906_104537_SV1-03_SV_RD_8bit_RGB_50cm_...           3007320   \n",
       "59_20221102_105437_SV2-01_SV_RD_8bit_RGB_50cm_E...           3494018   \n",
       "79_20220922_105204_SV1-04_SV_RD_8bit_RGB_50cm_C...           3132536   \n",
       "52_20221004_110216_SV1-03_SV_RD_8bit_RGB_50cm_W...           3199257   \n",
       "\n",
       "                                                                                             filename  \\\n",
       "66_20220903_111726_SV1-04_SV_RD_8bit_RGB_50cm_H...  66_20220903_111726_SV1-04_SV_RD_8bit_RGB_50cm_...   \n",
       "154_20220906_104537_SV1-03_SV_RD_8bit_RGB_50cm_...  154_20220906_104537_SV1-03_SV_RD_8bit_RGB_50cm...   \n",
       "59_20221102_105437_SV2-01_SV_RD_8bit_RGB_50cm_E...  59_20221102_105437_SV2-01_SV_RD_8bit_RGB_50cm_...   \n",
       "79_20220922_105204_SV1-04_SV_RD_8bit_RGB_50cm_C...  79_20220922_105204_SV1-04_SV_RD_8bit_RGB_50cm_...   \n",
       "52_20221004_110216_SV1-03_SV_RD_8bit_RGB_50cm_W...  52_20221004_110216_SV1-03_SV_RD_8bit_RGB_50cm_...   \n",
       "\n",
       "                                                   base64_img_data  \\\n",
       "66_20220903_111726_SV1-04_SV_RD_8bit_RGB_50cm_H...                   \n",
       "154_20220906_104537_SV1-03_SV_RD_8bit_RGB_50cm_...                   \n",
       "59_20221102_105437_SV2-01_SV_RD_8bit_RGB_50cm_E...                   \n",
       "79_20220922_105204_SV1-04_SV_RD_8bit_RGB_50cm_C...                   \n",
       "52_20221004_110216_SV1-03_SV_RD_8bit_RGB_50cm_W...                   \n",
       "\n",
       "                                                   file_attributes regions  \\\n",
       "66_20220903_111726_SV1-04_SV_RD_8bit_RGB_50cm_H...              {}      {}   \n",
       "154_20220906_104537_SV1-03_SV_RD_8bit_RGB_50cm_...              {}      {}   \n",
       "59_20221102_105437_SV2-01_SV_RD_8bit_RGB_50cm_E...              {}      {}   \n",
       "79_20220922_105204_SV1-04_SV_RD_8bit_RGB_50cm_C...              {}      {}   \n",
       "52_20221004_110216_SV1-03_SV_RD_8bit_RGB_50cm_W...              {}      {}   \n",
       "\n",
       "                                                    origin_x  origin_y  \n",
       "66_20220903_111726_SV1-04_SV_RD_8bit_RGB_50cm_H...   73790.0  442478.0  \n",
       "154_20220906_104537_SV1-03_SV_RD_8bit_RGB_50cm_...  242684.0  518504.0  \n",
       "59_20221102_105437_SV2-01_SV_RD_8bit_RGB_50cm_E...  160856.0  445873.0  \n",
       "79_20220922_105204_SV1-04_SV_RD_8bit_RGB_50cm_C...  246618.0  528318.0  \n",
       "52_20221004_110216_SV1-03_SV_RD_8bit_RGB_50cm_W...  154632.0  444063.5  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count amount of images with and without regions\n",
    "#split data into 2 dataframes: with and without annotations\n",
    "\n",
    "rows_empty_annot = []\n",
    "rows_annot = []\n",
    "i=0\n",
    "e=0\n",
    "\n",
    "# Initialize empty lists to store rows for images with and without annotations\n",
    "for index, row in train_df.iterrows():\n",
    "    if not row['regions']:\n",
    "        # Add row to new DataFrame\n",
    "        rows_empty_annot.append(row)\n",
    "        i+=1\n",
    "    else:\n",
    "        rows_annot.append(row)\n",
    "        e+=1\n",
    "        #print (row['regions'])     \n",
    "print(\"no regions: {}, with regions: {}\".format(i,e))\n",
    "\n",
    "# Create new DataFrames from the collected rows\n",
    "df_empty_annot = pd.DataFrame(rows_empty_annot, columns=train_df.columns)\n",
    "df_annot = pd.DataFrame(rows_annot, columns=train_df.columns)\n",
    "df_empty_annot.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9eb8ee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_25: 19803, train_50 39310, train_75: 58817\n"
     ]
    }
   ],
   "source": [
    "# Remove if run form beginning\n",
    "train_path = f\"../NSO/train\"\n",
    "\n",
    "# train_test split on train_df\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "test_sizes = [0.25, 0.5, 0.75]\n",
    "\n",
    "# Create an empty dictionary to store the DataFrames\n",
    "train_dic = {}\n",
    "\n",
    "for perc in test_sizes:\n",
    "    # Generate the name for the training DataFrame based on the perc amount\n",
    "    train_name = f\"train_{int((1 - perc) * 100)}\"\n",
    "    test_name = f\"test_{int((perc) * 100)}\"\n",
    "    # Split the DataFrame into training and test sets\n",
    "    train_set, test_set = train_test_split(df_empty_annot, test_size=perc, random_state=42)\n",
    "    train_dic[train_name] = pd.concat([df_annot, train_set])\n",
    "    #name tiles in index columns\n",
    "    data = train_dic[train_name].to_json(orient='index')\n",
    "    with open(os.path.join(train_path, f\"via_region_data_{train_name}_empty_annotations.json\"), \"w\") as outfile:\n",
    "        #.write to avoid {}\n",
    "        outfile.write(data)\n",
    "print (f\"train_25: {len(train_dic['train_25'])}, train_50 {len(train_dic['train_50'])}, train_75: {len(train_dic['train_75'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
